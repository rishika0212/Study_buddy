# OLLAMA Integration Configuration
# Copy this file to .env and adjust settings as needed

# OLLAMA Service
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=llama3

# Model Selection by Task Type
MODEL_EXPLANATION=llama3.1:8b
MODEL_MCQ_EVALUATION=llama3.2:3b
MODEL_QNA_EVALUATION=llama3.1:8b
MODEL_QUESTION_GENERATION=llama3.1:8b
MODEL_BRAINSTORM=llama3.1:8b

# Timeouts (seconds)
OLLAMA_TIMEOUT=30
MCQ_EVAL_TIMEOUT=5
GENERATION_TIMEOUT=60

# Retry Configuration
RETRY_ATTEMPTS=3
RETRY_DELAY=1.0

# Other Configuration
CHROMA_PERSIST_DIRECTORY=./data/chroma
USER_DATA_DIRECTORY=./data/users
LOG_LEVEL=INFO
